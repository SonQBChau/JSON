Data Engineer - Python

Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs.

We are seeking Software Engineers who are passionate about marrying data with emerging technologies to join our team. As a Capital One Software Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. Learn more about #lifeatcapitalone and our commitment to diversity & inclusion by jumping to slides 76-91 on our Corporate Social Responsibility Report.

What You’ll Do:

Collaborate with and across Agile teams to design, develop, test, implement, and support technical solutions in full-stack development tools and technologies

Work with a team of developers with deep experience in machine learning, distributed microservices, and full stack systems

Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal & external technology communities, and mentoring other members of the engineering community

Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment

Work with cloud native stack, build on AWS, use technologies like Kubernetes and Serverless

Basic Qualifications:

Bachelor’s Degree

At least 4 years of experience in software engineering

Preferred Qualifications:

Master's Degree

2+ years of experience in Agile practices

1+ years of experience with AWS, GCP, Microsoft Azure, or another public cloud service

4+ years of experience in at least one of the following: Java, Scala, Python, Go, Javascript/TypeScript, Angular/React.js, or Node.js

2+ years of experience working with big data technologies (e.g. Hadoop, Spark, Presto)

2+ years of experience working on streaming data applications (e.g. Kafka, Kinesis, Flink, or Spark Streaming)

4+ years of experience in open source frameworks

At this time, Capital One will not sponsor a new applicant for employment authorization for this position.


Intuit is looking for innovative and hands-on Staff Data scientist to join the Intuit AI team.This team embeds artificial intelligence and machine learning into our product portfolio and business to create smarter products, improve anti-fraud and security, and enhance customer care. We aim to save our customers time ("Never enter data"), increase their prosperity by making actionable financial recommendations, and enable them to have complete confidence in our products

What you'll bring
4+ years of industry experience with data science
BS, MS or PhD in Statistics, Mathematics, Computer Science, Economics, Operations Research, or equivalent
4+ years of hands-on expertise with data mining and statistical modeling techniques such as clustering, classification, regression, tree-based methods, neural nets, support vector machines, anomaly detection, and natural language processing
Expertise in modern advanced analytical tools and programming languages such as Python, Scala, Java and/or R.
Efficient in SQL, Hive, SparkSQL, etc.
Comfortable working in a Linux environment
Experience with building end-to-end reusable pipelines from data acquisition to model output delivery
Quick learner, adaptable, with the ability to work independently in a fast-paced environment
Strong oral and written communication skills. Ability to conduct meetings and make professional presentations, and to explain complex concepts and technical material to non-technical users
community
How you will lead

Excellent leadership and communication skills to influence teams and to evangelize data science across the organization
Perform hands-on data analysis and modeling with huge data sets
Apply data mining, NLP, and machine learning (both supervised and unsupervised) to improve relevance and personalization algorithms
Work side-by-side with product managers, software engineers, and designers in designing experiments and minimum viable products
Discover data sources, get access to them, import them, clean them up, and make them “model-ready”. You need to be willing and able to do your own ETL
Create and refine features from the underlying data. You’ll enjoy developing just enough subject matter expertise to have an intuition about what features might make your model perform better, and then you’ll lather, rinse and repeat
Run regular A/B tests, gather data, perform statistical analysis, draw conclusions on the impact of your optimizations and communicate results to peers and leaders
Explore new design or technology shifts in order to determine how they might connect with the customer benefits we wish to deliver
Communicate key analytic findings within the business and to senior stakeholders
Research, explore, and enable new quantitative techniques and technologies in data science

The Data Scientist will be joining a team of extremely passionate data scientists, product managers, and engineerswho share a common interest in tackling some of the most difficult data science and machine learning problems today. With the data products you design, 7Park will arm influential decision-makers at financial and corporate giants with critical information they need to make smart, data-driven decisions. Our technologies and data power the insights for financial services and corporations.

The compensation package includes a competitive salary and incentive structure, generous benefits, and valuable business experiences, challenges, and excitement of contributing to the success of a fast-growing technology startup.

As Data Scientists at 7Park Data, we design and build data products that provide rich intelligence on real-time economic activity for our financial and corporate clients. To do that, we research and develop machine learning systems to extract decision-ready insight from massive volumes of structured and unstructured data.

Responsibilities:
Building, testing and maintaining all the components of 7Park Data’s product pipelines:
o Developing the transformation and enrichment logic that prepares messy, incomplete and inconsistent data for analysis

o Applying statistical modelling techniques to produce signals and packaging them in a client-consumable output
Work with 7Park Product and Commercial teams to understand business requirements, and their context, then translate them to a technical plan of action.
Evaluate new vendor data as part of our data acquisition process, form opinions on its future business value and the likelihood of success, and ultimately communicate findings to stakeholders at all levels of seniority
Collaborate with our Financial Research team to investigate hypotheses, produce commentaries and analyses on market trends, as well as refining new and existing products
Work with Product Managers at a strategic level to plan product roadmaps, recommend new products or enhancements, as well as estimating and prioritizing work. Ensure alignment of day-to-day activity with the overall product strategy
Develop systems to monitor the analytical quality of production models to discover anomalies, following through to investigation and resolution
Create technical documentation for both internal and external technical audiences, as well as contributing to client-facing content for non-technical audiences
Requirements:
3 – 5 years of relevant professional experience in an autonomous data analytics or data science role
Master’s degree or PhD in computer science, mathematics, statistics, physics, computational finance, or a similar quantitative field (or relevant work experience)
Knowledge of statistics, computer science and machine learning
Strong programming skills in Python (highly preferred), R, and/or Scala
Strong proficiency with Pandas and Scikit-Learn
Experience with building distributed data pipelines using PySpark
Experience with several of the following concepts: decision trees, random forests, gradient boosting; linear regression; logistic regression; dimensionality reduction using PCA and clustering
Comfortable with general SDLC concepts and processes
Results-driven attitude with a strong desire to build data products and achieve results that matter- for us and for our clients. We come to play and play to win.
Deeply held conviction for the power of data, with high analytical standards and surgical attention to detail
Fearlessness in the pursuit of process improvement, implementation, and change
Flexibility and willingness to adapt to the changing demands of a fast-paced startup environment
Solutions oriented approach and multi-dimensional problem solving
Highly self-motivated and results oriented, proven track record of exceeding goals
Commitment to success and willingness to put forth the effort to achieve it
Strong written and verbal English communication skills – ability to communicate complex ideas simply and accurately to technical and non-technical audiences
